{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23100868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summarization model loaded and ready to use.\n"
     ]
    }
   ],
   "source": [
    "# üìå Cell 1: Setup and Load Pretrained Summarization Model\n",
    "\n",
    "# Install required libraries if not already installed\n",
    "#!pip install transformers torch --quiet\n",
    "\n",
    "# Import necessary modules\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a powerful summarization pipeline using Facebook's BART large CNN model\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "print(\"‚úÖ Summarization model loaded and ready to use.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ff9d067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 1024, but your input_length is only 163. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=81)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Original Text:\n",
      " \n",
      "In the age of information overload, summarization tools are increasingly vital for digesting massive volumes of text quickly and efficiently. \n",
      "Modern natural language processing (NLP) techniques leverage large pretrained models to extract and condense key information from documents, \n",
      "news articles, research papers, and more. These models are trained on diverse datasets and can understand the nuances of human language, \n",
      "producing summaries that are coherent and contextually relevant. One of the leading models in this domain is Facebook's BART, which has \n",
      "achieved state-of-the-art results in text summarization tasks. By integrating such models into easy-to-use tools, both individuals and \n",
      "organizations can save time, enhance productivity, and make informed decisions based on concise insights.\n",
      "\n",
      "\n",
      "üîπ Generated Summary:\n",
      " In the age of information overload, summarization tools are increasingly vital for digesting massive volumes of text quickly and efficiently. One of the leading models in this domain is Facebook's BART, which has achieved state-of-the-art results in text summarization tasks.\n"
     ]
    }
   ],
   "source": [
    "# üìå Cell 2: Input Lengthy Article and Generate Summary\n",
    "\n",
    "# Example lengthy text (replace with any article)\n",
    "article_text = \"\"\"\n",
    "In the age of information overload, summarization tools are increasingly vital for digesting massive volumes of text quickly and efficiently. \n",
    "Modern natural language processing (NLP) techniques leverage large pretrained models to extract and condense key information from documents, \n",
    "news articles, research papers, and more. These models are trained on diverse datasets and can understand the nuances of human language, \n",
    "producing summaries that are coherent and contextually relevant. One of the leading models in this domain is Facebook's BART, which has \n",
    "achieved state-of-the-art results in text summarization tasks. By integrating such models into easy-to-use tools, both individuals and \n",
    "organizations can save time, enhance productivity, and make informed decisions based on concise insights.\n",
    "\"\"\"\n",
    "\n",
    "# Generate summary with practical high max_length\n",
    "summary = summarizer(\n",
    "    article_text,\n",
    "    min_length=10,    # minimum summary length\n",
    "    max_length=1024,  # high value to avoid cutting off too soon\n",
    "    do_sample=False   # deterministic output\n",
    ")\n",
    "\n",
    "print(\"üîπ Original Text:\\n\", article_text)\n",
    "print(\"\\nüîπ Generated Summary:\\n\", summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9439f1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded article from 'article.txt'\n",
      "\n",
      "üîπ Article Preview (first 500 characters):\n",
      "One of India‚Äôs greatest assets is youth. Jayan Jose Thomas calls for changes in established thinking to harness its potential.\n",
      "\n",
      "India, like many South Asian countries, has a young population. This is at once an opportunity for future economic growth, but it presents policymakers with the challenge of creating employment. According to the World Bank, the projected increase in South Asia‚Äôs working-age population during 2020-2050 is some 254.m accounting for 30.6% of the increase worldwide. India a...\n"
     ]
    }
   ],
   "source": [
    "# üìå Cell 3: Load Article from File or Manual Input\n",
    "\n",
    "import os\n",
    "\n",
    "# Option 1: Load from a .txt file\n",
    "file_path = \"article.txt\"  # Replace with your file name\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        article_text = file.read()\n",
    "    print(f\"‚úÖ Loaded article from '{file_path}'\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è File '{file_path}' not found. Using manual input instead.\")\n",
    "    # Option 2: Manual input fallback\n",
    "    article_text = input(\"Please paste your article text here:\\n\")\n",
    "\n",
    "print(\"\\nüîπ Article Preview (first 500 characters):\")\n",
    "print(article_text[:500] + (\"...\" if len(article_text) > 500 else \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df0ec913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Splitting article into 3 chunk(s) for safe summarization.\n",
      "\n",
      "üîπ Summarizing chunk 1/3...\n",
      "üîπ Summarizing chunk 2/3...\n",
      "üîπ Summarizing chunk 3/3...\n",
      "\n",
      "üîπ Final Combined Summary:\n",
      "\n",
      "Jayan Jose Thomas calls for changes in established thinking to harness its potential. India, like many South Asian countries, has a young population. Increasing enrolment in education and a growing exodus of young people from agriculture are swelling the jobless ranks.\n",
      "\n",
      "Of India‚Äôs total workforce of 471.0 million, only 12.3% are regular workers who receive some form of social security and are covered, at least partially, by laws that protect labour rights. The rest are mostly casual workers or petty producers surviving under various degrees of informality.\n",
      "\n",
      "India‚Äôs working classes deserve real improvements in living and working conditions. This can happen only with a massive expansion in government spending. Proposals might include the setting up of industries linked to food processing or affordable housing in rural areas.\n"
     ]
    }
   ],
   "source": [
    "# üìå Cell 4: Robust Summarization with CPU and Chunking\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "# Force summarizer to run on CPU to avoid CUDA errors\n",
    "summarizer_cpu = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"facebook/bart-large-cnn\",\n",
    "    device=-1  # -1 means CPU\n",
    ")\n",
    "\n",
    "# BART max input length: ~1024 tokens (~1024 words for English)\n",
    "max_chunk_words = 500  # safe chunk size\n",
    "\n",
    "# Split text into chunks\n",
    "words = article_text.split()\n",
    "num_chunks = ceil(len(words) / max_chunk_words)\n",
    "chunks = [\n",
    "    \" \".join(words[i*max_chunk_words : (i+1)*max_chunk_words])\n",
    "    for i in range(num_chunks)\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Splitting article into {num_chunks} chunk(s) for safe summarization.\\n\")\n",
    "\n",
    "# Summarize each chunk, then join results\n",
    "summaries = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"üîπ Summarizing chunk {i+1}/{num_chunks}...\")\n",
    "    summary = summarizer_cpu(\n",
    "        chunk,\n",
    "        min_length=10,\n",
    "        max_length=200,   # smaller chunk summary\n",
    "        do_sample=False\n",
    "    )\n",
    "    summaries.append(summary[0]['summary_text'])\n",
    "\n",
    "# Combine summaries\n",
    "final_summary = \"\\n\\n\".join(summaries)\n",
    "\n",
    "print(\"\\nüîπ Final Combined Summary:\\n\")\n",
    "print(final_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83ee22c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary saved successfully to 'summary.txt'\n"
     ]
    }
   ],
   "source": [
    "# üìå Cell 5: Save Final Summary to File\n",
    "\n",
    "output_file = \"summary.txt\"\n",
    "\n",
    "try:\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(final_summary)\n",
    "    print(f\"‚úÖ Summary saved successfully to '{output_file}'\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Failed to save summary: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
